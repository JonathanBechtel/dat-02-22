{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unit 1 Homework:  Scraping the Yelp Website\n",
    "\n",
    "Welcome!  For this homework assignment you'll be tasked with building a web scraper in a manner that builds on what was covered in our web scraping class.\n",
    "\n",
    "The assignment will extend the lab work done during that time, where we built a dataset that listed the name, number of reviews and price range for restaurant on the following web page: https://www.yelp.com/search?find_desc=Restaurants&find_loc=London%2C%20United%20Kingdom&ns=1\n",
    "\n",
    "**What You'll Turn In:**\n",
    "\n",
    "A finished jupyter notebook that walks us through the steps you took in order to get your results.  Provide notes where appropriate to explain what you are doing.\n",
    "\n",
    "The notebook should produce a finished dataset at the end.  \n",
    "\n",
    "If for some reason you're experiencing problems with the final result, please let someone know when turning it in.\n",
    " \n",
    "The homework is divided into five tiers, each of which have increasing levels of difficulty:\n",
    "\n",
    "##### Tier 1: Five Columns From the First Page\n",
    "\n",
    "At the most basic level for this assignment, you will need to extend what we did in class, and create a dataset that has five columns in it that are 30 rows long.  This means you will not need to go off the first page in order to complete this section.\n",
    "\n",
    "##### Tier 2:  100 Row Dataset With At Least 3 Columns\n",
    "\n",
    "For this portion of the assignment, take 3 of your columns from step 1, and extend them out to multiple pages on the yelp website.  You should appropriately account for the presence of missing values.\n",
    "\n",
    "##### Tier 3:  100 Row Dataset With At Least 5 Columns\n",
    "\n",
    "Very similar to Tier 2, but if you use this many columns you will be forced to encounter some columns that will frequently have missing values, whereas with Tier 2 you could likely skip these if you wanted to.  \n",
    "\n",
    "##### Tier 4:  100 Row Dataset With At Least 5 Columns + Individual Restaurant Categories\n",
    "\n",
    "Restaurants often have different categories associated with them, so grabbing them individually as separate values is often challenging.  To complete this tier, you'll have to find a way to 'pick out' each of the individual categories as their own separate column value.  \n",
    "\n",
    "##### Tier 5:  Unlimited Row Dataset With At Least 5 Columns + Individual Restaurant Categories\n",
    "\n",
    "Take what you did in Tier 4, and extend it so that the code will work with an arbitrary number of pages.  Ie, regardless of how many pages there are listing the best restaurants in London, your scraper will find them, and cleanly parse their information into clean datasets.\n",
    "\n",
    "### Hints\n",
    "\n",
    "Here are a few tips that will save you time when completing this assignment:\n",
    "\n",
    " - The name, average rating, total ratings and neighborhood of a restaurant tend to be the 'easy' ones, because they rarely have missing values, so what ever logic you use on the first page will typically apply to all pages.  They are a good place to start\n",
    " - Phone numbers, price ranges and reviews are more commonly missing, so if you are trying to get a larger number of items from them across multiple pages you should expect to do some error handling\n",
    " - You can specify any sort of selector when using the `find_all()` method, not just `class`.  For example, imagine you have the following `<div>` tag:\n",
    "    `<div class='main-container red-blue-green' role='front-unit' aria-select='left-below'>Some content here</div>`\n",
    "    \n",
    "   This means that when you use `scraper.find_all('div')`, you can pass in arguments like `scraper.find_all('div', {'role': 'front-unit'})` or anything else that allows you to isolate that particular tag.\n",
    " - When specifying selectors like `{'class': 'dkght__384Ko'}`, sometimes less is more.  If you include multiple selectors, you are saying return a tag with **any one of these** distinctions, not all of them.  So if your results are large, try different combinations of selectors to get the smallest results possible.\n",
    " - If you begin dealing with values that are unreliably entered, you should use the 'outside in' technique where you grab a parent container that holds the element and find a way to check to see if a particular value is there by scraping it further.  The best way to do this is to try and find a unique container for every single restaurant.  This means that you will have a reliable parent element for every single restaurant, and within *each of these* you can search for `<p>`, `<a>`, `<div>`, and `<span>` tags and apply further logic.\n",
    " - When you get results from `BeautifulSoup`, you will be given data that's denoted as either `bs4.element.Tag` or `bs4.element.ResultSet`.  They are **not the same**.  Critically, you can search a `bs4.element.Tag` for further items, but you cannot do this with a `bs4.element.ResultSet`.  \n",
    " \n",
    "   For example, let's say you grab all of the divs from a page with `scraper.find_all('div')` and save it as the variable `total_divs`.  This means `total_divs` will look somethig like this:  \n",
    "   \n",
    "   `[<div><p>Div content</p><p>Second paragraph</p></div>,`\n",
    "      `<div><p>Div content</p><p>Second paragraph</p></div>,`\n",
    "      `<div><p>Div content</p><p>Second paragraph</p></div>]`\n",
    "      \n",
    "   In this case the variable `total_divs` is a result set and there's nothing else you can do to it directly.  However, every item within `total_divs` is a tag, which means you can scrape it further.  \n",
    "   \n",
    "   So if you wanted you could write a line like:  `total_paragraphs = [div.find_all('p') for div in total_divs]`, and get the collection of paragraphs within each div.  \n",
    "   \n",
    "   If you confuse the two you'll get the following error message:  \n",
    "   \n",
    "   `AttributeError: ResultSet object has no attribute 'find_all'. You're probably treating a list of elements like a single element. Did you call find_all() when you meant to call find()?`\n",
    " - The values of the different selectors change periodically on yelp, so if your scraper all of a sudden stops working that's probably why.  Ie, if you have a command like `scraper.find_all('div', {'class': '485dk0W__container09'}` that no longer returns results, the class `485dk0W__container09` may now be `r56kW__container14` or something similar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "#scrape multiple pages\n",
    "page_ranges = [0,10,20]\n",
    "\n",
    "#create new lists for scraped data\n",
    "all_names = []\n",
    "num_reviews  = []\n",
    "price_ranges = []\n",
    "all_paragraphs = []\n",
    "num_stars = []\n",
    "\n",
    "#allow scraping to search multiple pages\n",
    "for i in page_ranges:\n",
    "    url = (f'https://www.yelp.com/search?find_desc=Restaurants&find_loc=London%2C%20United%20Kingdom&ns=1&start={i}')\n",
    "    yelp_req= requests.get(url).text\n",
    "    scraper= BeautifulSoup(yelp_req)\n",
    "    #scrape names of each restaurant\n",
    "    names=scraper.find_all('a',{'class': 'css-166la90'})\n",
    "    names = [name.text for name in names]\n",
    "    names=[name for name in names if len(name)>1]\n",
    "    all_names += names\n",
    "    #scrape number of reviews for each restaurant\n",
    "    reviews=scraper.find_all('span', {'class':'reviewCount__09f24__EUXPN'})\n",
    "    reviews = [int(review.text) for review in reviews]\n",
    "    num_reviews += reviews\n",
    "    #scrape price range for each restaurant\n",
    "    prices=scraper.find_all('span', {'class':'priceRange__09f24__2O6le css-xtpg8e'})\n",
    "    prices = [str(price.text) for price in prices]\n",
    "    price_ranges += prices\n",
    "    #scrape the first review for each restaurant\n",
    "    paragraphs=scraper.find_all('p',{'class': 'css-e81eai'})\n",
    "    paragraphs = [str(paragraph.text) for paragraph in paragraphs]\n",
    "    paragraphs=[paragraph for paragraph in paragraphs if len(paragraph)>1]\n",
    "    paragraphs = [text.replace('\\xa0more','') for text in paragraphs[:10]]\n",
    "    all_paragraphs += paragraphs\n",
    "    #scrape the star rating for each restaurant\n",
    "    ratings=scraper.find_all('div',{'class': 'i-stars__09f24__1T6rz'})\n",
    "    ratings = [float(item['aria-label'].split()[0]) for item in ratings]\n",
    "    num_stars += ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Number of Ratings</th>\n",
       "      <th>Price Range</th>\n",
       "      <th>Number of Stars</th>\n",
       "      <th>First Review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The Mayfair Chippy</td>\n",
       "      <td>282</td>\n",
       "      <td>££</td>\n",
       "      <td>4.5</td>\n",
       "      <td>“One of the best fish ever with the most tasty...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Dishoom</td>\n",
       "      <td>1841</td>\n",
       "      <td>££</td>\n",
       "      <td>4.5</td>\n",
       "      <td>“Hard to find a way to add any higher praise t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The Breakfast Club</td>\n",
       "      <td>494</td>\n",
       "      <td>££</td>\n",
       "      <td>4.0</td>\n",
       "      <td>“By far one of my most favorite breakfast plac...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Flat Iron</td>\n",
       "      <td>380</td>\n",
       "      <td>££</td>\n",
       "      <td>4.5</td>\n",
       "      <td>“Went to London for vacation and stopped by th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ffiona’s Restaurant</td>\n",
       "      <td>267</td>\n",
       "      <td>££</td>\n",
       "      <td>4.5</td>\n",
       "      <td>“Ffiona's is easily my favorite restaurant in ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Dishoom</td>\n",
       "      <td>547</td>\n",
       "      <td>££</td>\n",
       "      <td>4.5</td>\n",
       "      <td>“I visited Dishoom during my recent London tri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>The Fat Bear</td>\n",
       "      <td>122</td>\n",
       "      <td>££</td>\n",
       "      <td>4.5</td>\n",
       "      <td>“WOW, this place is delicious!\\n\\nOur family s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Restaurant Gordon Ramsay</td>\n",
       "      <td>204</td>\n",
       "      <td>££££</td>\n",
       "      <td>4.5</td>\n",
       "      <td>“Compared to Michelin 3-star restaurants in Ca...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Mother Mash</td>\n",
       "      <td>470</td>\n",
       "      <td>££</td>\n",
       "      <td>4.0</td>\n",
       "      <td>“Soho is full of culture and amazing places to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>NOPI</td>\n",
       "      <td>272</td>\n",
       "      <td>£££</td>\n",
       "      <td>4.5</td>\n",
       "      <td>“10/10 recommend!\\nGood cocktails to have as a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Sketch</td>\n",
       "      <td>826</td>\n",
       "      <td>£££</td>\n",
       "      <td>4.0</td>\n",
       "      <td>“Having received it's 3rd star in 2020, sketch...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>The Golden Chippy</td>\n",
       "      <td>106</td>\n",
       "      <td>££</td>\n",
       "      <td>5.0</td>\n",
       "      <td>“The hype is REAL! The Golden Chippy is truly ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Honest Burgers Meard St - Soho</td>\n",
       "      <td>278</td>\n",
       "      <td>££</td>\n",
       "      <td>4.5</td>\n",
       "      <td>“Best burgers  \\nAmazing and friendly staff.\\n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Padella</td>\n",
       "      <td>206</td>\n",
       "      <td>££</td>\n",
       "      <td>4.5</td>\n",
       "      <td>“A great dining experience even in COVID times...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Regency Café</td>\n",
       "      <td>392</td>\n",
       "      <td>£</td>\n",
       "      <td>4.5</td>\n",
       "      <td>“Heads up: Cash only!\\n\\nAn overall great expe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>BAO - Soho</td>\n",
       "      <td>184</td>\n",
       "      <td>££</td>\n",
       "      <td>4.0</td>\n",
       "      <td>“Walked past the queues several times, getting...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Mestizo</td>\n",
       "      <td>152</td>\n",
       "      <td>££</td>\n",
       "      <td>4.0</td>\n",
       "      <td>“As of food concern, I experienced authentic f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Lanzhou Noodle Bar</td>\n",
       "      <td>351</td>\n",
       "      <td>£</td>\n",
       "      <td>4.0</td>\n",
       "      <td>“We got to our hotel somewhere in between earl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>The Queens Arms</td>\n",
       "      <td>120</td>\n",
       "      <td>££</td>\n",
       "      <td>4.5</td>\n",
       "      <td>“Hands down the best bread and olives combinat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Hawksmoor Seven Dials</td>\n",
       "      <td>342</td>\n",
       "      <td>£££</td>\n",
       "      <td>4.5</td>\n",
       "      <td>“preamble:  We were in London for four days an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Abeno</td>\n",
       "      <td>101</td>\n",
       "      <td>££</td>\n",
       "      <td>4.5</td>\n",
       "      <td>“This place was amazing! Some of the best serv...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Yauatcha</td>\n",
       "      <td>480</td>\n",
       "      <td>£££</td>\n",
       "      <td>4.0</td>\n",
       "      <td>“Well... had to try this high end dim sum plac...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Duck &amp; Waffle</td>\n",
       "      <td>705</td>\n",
       "      <td>£££</td>\n",
       "      <td>4.0</td>\n",
       "      <td>“Duck &amp; Waffle would make an amazing date spot...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Wahaca</td>\n",
       "      <td>310</td>\n",
       "      <td>££</td>\n",
       "      <td>4.0</td>\n",
       "      <td>“I stumbled upon Wahaca walking home from work...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>The Palomar Restaurant</td>\n",
       "      <td>104</td>\n",
       "      <td>£££</td>\n",
       "      <td>4.5</td>\n",
       "      <td>“Unmatched flavors and service!\\n\\nHighly reco...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Barrafina</td>\n",
       "      <td>59</td>\n",
       "      <td>££</td>\n",
       "      <td>4.5</td>\n",
       "      <td>“Wow, a great spot. Super busy, even on a Mond...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Blacklock</td>\n",
       "      <td>109</td>\n",
       "      <td>£££</td>\n",
       "      <td>4.5</td>\n",
       "      <td>“Visited London and told the wife that we had ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Kennington Lane Cafe</td>\n",
       "      <td>96</td>\n",
       "      <td>£</td>\n",
       "      <td>5.0</td>\n",
       "      <td>“Superb English Breakfast! Best I have had in ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Burger &amp; Lobster</td>\n",
       "      <td>291</td>\n",
       "      <td>££</td>\n",
       "      <td>4.0</td>\n",
       "      <td>“G was a wonderful server. She was kind and bu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>The English Rose Cafe and Tea Shop</td>\n",
       "      <td>213</td>\n",
       "      <td>££</td>\n",
       "      <td>4.5</td>\n",
       "      <td>“While traveling through London my husband wan...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 Title  Number of Ratings Price Range  \\\n",
       "0                   The Mayfair Chippy                282          ££   \n",
       "1                              Dishoom               1841          ££   \n",
       "2                   The Breakfast Club                494          ££   \n",
       "3                            Flat Iron                380          ££   \n",
       "4                  Ffiona’s Restaurant                267          ££   \n",
       "5                              Dishoom                547          ££   \n",
       "6                         The Fat Bear                122          ££   \n",
       "7             Restaurant Gordon Ramsay                204        ££££   \n",
       "8                          Mother Mash                470          ££   \n",
       "9                                 NOPI                272         £££   \n",
       "10                              Sketch                826         £££   \n",
       "11                   The Golden Chippy                106          ££   \n",
       "12      Honest Burgers Meard St - Soho                278          ££   \n",
       "13                             Padella                206          ££   \n",
       "14                        Regency Café                392           £   \n",
       "15                          BAO - Soho                184          ££   \n",
       "16                             Mestizo                152          ££   \n",
       "17                  Lanzhou Noodle Bar                351           £   \n",
       "18                     The Queens Arms                120          ££   \n",
       "19               Hawksmoor Seven Dials                342         £££   \n",
       "20                               Abeno                101          ££   \n",
       "21                            Yauatcha                480         £££   \n",
       "22                       Duck & Waffle                705         £££   \n",
       "23                              Wahaca                310          ££   \n",
       "24              The Palomar Restaurant                104         £££   \n",
       "25                           Barrafina                 59          ££   \n",
       "26                           Blacklock                109         £££   \n",
       "27                Kennington Lane Cafe                 96           £   \n",
       "28                    Burger & Lobster                291          ££   \n",
       "29  The English Rose Cafe and Tea Shop                213          ££   \n",
       "\n",
       "    Number of Stars                                       First Review  \n",
       "0               4.5  “One of the best fish ever with the most tasty...  \n",
       "1               4.5  “Hard to find a way to add any higher praise t...  \n",
       "2               4.0  “By far one of my most favorite breakfast plac...  \n",
       "3               4.5  “Went to London for vacation and stopped by th...  \n",
       "4               4.5  “Ffiona's is easily my favorite restaurant in ...  \n",
       "5               4.5  “I visited Dishoom during my recent London tri...  \n",
       "6               4.5  “WOW, this place is delicious!\\n\\nOur family s...  \n",
       "7               4.5  “Compared to Michelin 3-star restaurants in Ca...  \n",
       "8               4.0  “Soho is full of culture and amazing places to...  \n",
       "9               4.5  “10/10 recommend!\\nGood cocktails to have as a...  \n",
       "10              4.0  “Having received it's 3rd star in 2020, sketch...  \n",
       "11              5.0  “The hype is REAL! The Golden Chippy is truly ...  \n",
       "12              4.5  “Best burgers  \\nAmazing and friendly staff.\\n...  \n",
       "13              4.5  “A great dining experience even in COVID times...  \n",
       "14              4.5  “Heads up: Cash only!\\n\\nAn overall great expe...  \n",
       "15              4.0  “Walked past the queues several times, getting...  \n",
       "16              4.0  “As of food concern, I experienced authentic f...  \n",
       "17              4.0  “We got to our hotel somewhere in between earl...  \n",
       "18              4.5  “Hands down the best bread and olives combinat...  \n",
       "19              4.5  “preamble:  We were in London for four days an...  \n",
       "20              4.5  “This place was amazing! Some of the best serv...  \n",
       "21              4.0  “Well... had to try this high end dim sum plac...  \n",
       "22              4.0  “Duck & Waffle would make an amazing date spot...  \n",
       "23              4.0  “I stumbled upon Wahaca walking home from work...  \n",
       "24              4.5  “Unmatched flavors and service!\\n\\nHighly reco...  \n",
       "25              4.5  “Wow, a great spot. Super busy, even on a Mond...  \n",
       "26              4.5  “Visited London and told the wife that we had ...  \n",
       "27              5.0  “Superb English Breakfast! Best I have had in ...  \n",
       "28              4.0  “G was a wonderful server. She was kind and bu...  \n",
       "29              4.5  “While traveling through London my husband wan...  "
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create new dictionary for each item\n",
    "df_dict = {\n",
    "    'Title': all_names,\n",
    "    'Number of Ratings': num_reviews,\n",
    "    'Price Range': price_ranges,\n",
    "    'Number of Stars':num_stars,\n",
    "    'First Review':all_paragraphs\n",
    "}\n",
    "#create table format\n",
    "pd.DataFrame(df_dict)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
